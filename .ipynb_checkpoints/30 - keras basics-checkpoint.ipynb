{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd83821-9f8c-47dd-a7a0-cc57708a0384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b673423c-d566-4db2-a187-5b57efad86ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699,   0.     ],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ,   0.     ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645,   0.     ],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ,   1.     ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ,   1.     ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ,   1.     ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = genfromtxt(\"course material/DATA/bank_note_data.txt\", delimiter=\",\")\n",
    "data #the last column is a class (label), the others are features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680adc66-7f04-4a1e-a710-29fc5205cd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data[:,4]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b45e61f-c059-478b-8dc8-cf3a2d155628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data[:,0:4]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f651152a-c9ba-4022-988c-1dadc615b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convention\n",
    "X = features\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b3c723-946d-482a-b10b-f8f250bf99d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(919, 1372, 453)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split data in train and set\n",
    "from sklearn.model_selection import train_test_split\n",
    "#33% of data is test, random_state is force a specific random each time, 42 is because is the \"answer of everything\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "len(X_train), len(X), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e655dceb-fabf-4889-89fa-7b3c3aadc9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000000000000002, 17.9274)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_object = MinMaxScaler()\n",
    "#we just adjust X_train, because adjusting X_test is cheating, you cannot assume MaxMin from the tests because it is unknown data, so we don't do it with the whole database\n",
    "scaler_object.fit(X_train) \n",
    "scaler_object.transform(X_train)\n",
    "scaled_X_train = scaler_object.transform(X_train)\n",
    "scaled_X_test = scaler_object.transform(X_test)\n",
    "scaled_X_train.max(), X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28bb0dd2-0440-4499-ae36-9a1e99ef0e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 20:51:01.818420: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f227b52-8a3c-49ae-b034-de06b7ab9f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 20:54:40.924002: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=4, activation=\"relu\")) #4 because is four features, relu because whant only positive values\n",
    "model.add(Dense(8, activation=\"relu\")) #2x the size of before, can be 3x or any rule, but more is not better\n",
    "model.add(Dense(1, activation=\"sigmoid\")) #sigmoid because output will be zero or one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b049cefb-7ef4-407d-8d63-257c2dcd575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 - 0s - loss: 0.1233 - accuracy: 0.9695 - 464ms/epoch - 16ms/step\n",
      "Epoch 2/100\n",
      "29/29 - 0s - loss: 0.1189 - accuracy: 0.9706 - 31ms/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "29/29 - 0s - loss: 0.1146 - accuracy: 0.9750 - 38ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "29/29 - 0s - loss: 0.1102 - accuracy: 0.9750 - 32ms/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "29/29 - 0s - loss: 0.1061 - accuracy: 0.9761 - 38ms/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "29/29 - 0s - loss: 0.1025 - accuracy: 0.9761 - 49ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "29/29 - 0s - loss: 0.0986 - accuracy: 0.9761 - 35ms/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "29/29 - 0s - loss: 0.0956 - accuracy: 0.9793 - 41ms/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "29/29 - 0s - loss: 0.0921 - accuracy: 0.9804 - 49ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "29/29 - 0s - loss: 0.0886 - accuracy: 0.9804 - 41ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "29/29 - 0s - loss: 0.0861 - accuracy: 0.9804 - 36ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "29/29 - 0s - loss: 0.0832 - accuracy: 0.9815 - 37ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "29/29 - 0s - loss: 0.0806 - accuracy: 0.9826 - 42ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "29/29 - 0s - loss: 0.0779 - accuracy: 0.9826 - 40ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "29/29 - 0s - loss: 0.0757 - accuracy: 0.9826 - 35ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "29/29 - 0s - loss: 0.0733 - accuracy: 0.9859 - 39ms/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "29/29 - 0s - loss: 0.0711 - accuracy: 0.9848 - 39ms/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "29/29 - 0s - loss: 0.0690 - accuracy: 0.9869 - 35ms/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "29/29 - 0s - loss: 0.0671 - accuracy: 0.9880 - 38ms/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "29/29 - 0s - loss: 0.0651 - accuracy: 0.9891 - 40ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "29/29 - 0s - loss: 0.0634 - accuracy: 0.9891 - 53ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "29/29 - 0s - loss: 0.0618 - accuracy: 0.9902 - 39ms/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "29/29 - 0s - loss: 0.0599 - accuracy: 0.9924 - 36ms/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "29/29 - 0s - loss: 0.0585 - accuracy: 0.9924 - 46ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "29/29 - 0s - loss: 0.0567 - accuracy: 0.9935 - 44ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "29/29 - 0s - loss: 0.0549 - accuracy: 0.9935 - 66ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "29/29 - 0s - loss: 0.0530 - accuracy: 0.9935 - 48ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "29/29 - 0s - loss: 0.0518 - accuracy: 0.9935 - 43ms/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "29/29 - 0s - loss: 0.0502 - accuracy: 0.9946 - 49ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "29/29 - 0s - loss: 0.0493 - accuracy: 0.9946 - 61ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "29/29 - 0s - loss: 0.0481 - accuracy: 0.9935 - 90ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "29/29 - 0s - loss: 0.0470 - accuracy: 0.9956 - 41ms/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "29/29 - 0s - loss: 0.0458 - accuracy: 0.9956 - 42ms/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "29/29 - 0s - loss: 0.0447 - accuracy: 0.9946 - 38ms/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "29/29 - 0s - loss: 0.0435 - accuracy: 0.9956 - 46ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "29/29 - 0s - loss: 0.0424 - accuracy: 0.9956 - 41ms/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "29/29 - 0s - loss: 0.0414 - accuracy: 0.9956 - 43ms/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "29/29 - 0s - loss: 0.0406 - accuracy: 0.9956 - 37ms/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "29/29 - 0s - loss: 0.0399 - accuracy: 0.9956 - 45ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "29/29 - 0s - loss: 0.0389 - accuracy: 0.9956 - 37ms/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "29/29 - 0s - loss: 0.0382 - accuracy: 0.9956 - 52ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "29/29 - 0s - loss: 0.0374 - accuracy: 0.9956 - 39ms/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "29/29 - 0s - loss: 0.0365 - accuracy: 0.9956 - 42ms/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "29/29 - 0s - loss: 0.0359 - accuracy: 0.9956 - 36ms/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "29/29 - 0s - loss: 0.0352 - accuracy: 0.9956 - 56ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "29/29 - 0s - loss: 0.0346 - accuracy: 0.9956 - 61ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "29/29 - 0s - loss: 0.0338 - accuracy: 0.9956 - 51ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "29/29 - 0s - loss: 0.0330 - accuracy: 0.9956 - 40ms/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "29/29 - 0s - loss: 0.0325 - accuracy: 0.9956 - 45ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "29/29 - 0s - loss: 0.0323 - accuracy: 0.9956 - 41ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "29/29 - 0s - loss: 0.0320 - accuracy: 0.9956 - 38ms/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "29/29 - 0s - loss: 0.0309 - accuracy: 0.9956 - 39ms/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "29/29 - 0s - loss: 0.0307 - accuracy: 0.9956 - 37ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "29/29 - 0s - loss: 0.0296 - accuracy: 0.9967 - 38ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "29/29 - 0s - loss: 0.0295 - accuracy: 0.9967 - 37ms/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "29/29 - 0s - loss: 0.0291 - accuracy: 0.9956 - 41ms/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "29/29 - 0s - loss: 0.0288 - accuracy: 0.9956 - 75ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "29/29 - 0s - loss: 0.0277 - accuracy: 0.9967 - 71ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "29/29 - 0s - loss: 0.0277 - accuracy: 0.9967 - 36ms/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "29/29 - 0s - loss: 0.0276 - accuracy: 0.9967 - 40ms/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "29/29 - 0s - loss: 0.0267 - accuracy: 0.9967 - 43ms/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "29/29 - 0s - loss: 0.0265 - accuracy: 0.9967 - 46ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "29/29 - 0s - loss: 0.0258 - accuracy: 0.9967 - 46ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "29/29 - 0s - loss: 0.0257 - accuracy: 0.9967 - 35ms/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "29/29 - 0s - loss: 0.0251 - accuracy: 0.9967 - 41ms/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "29/29 - 0s - loss: 0.0250 - accuracy: 0.9967 - 34ms/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "29/29 - 0s - loss: 0.0250 - accuracy: 0.9967 - 39ms/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "29/29 - 0s - loss: 0.0245 - accuracy: 0.9967 - 67ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "29/29 - 0s - loss: 0.0242 - accuracy: 0.9967 - 49ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "29/29 - 0s - loss: 0.0237 - accuracy: 0.9967 - 59ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "29/29 - 0s - loss: 0.0234 - accuracy: 0.9967 - 42ms/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "29/29 - 0s - loss: 0.0232 - accuracy: 0.9967 - 37ms/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "29/29 - 0s - loss: 0.0230 - accuracy: 0.9967 - 44ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "29/29 - 0s - loss: 0.0227 - accuracy: 0.9967 - 36ms/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "29/29 - 0s - loss: 0.0224 - accuracy: 0.9967 - 42ms/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "29/29 - 0s - loss: 0.0221 - accuracy: 0.9967 - 37ms/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "29/29 - 0s - loss: 0.0217 - accuracy: 0.9967 - 45ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "29/29 - 0s - loss: 0.0213 - accuracy: 0.9967 - 35ms/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "29/29 - 0s - loss: 0.0211 - accuracy: 0.9967 - 37ms/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "29/29 - 0s - loss: 0.0210 - accuracy: 0.9967 - 34ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "29/29 - 0s - loss: 0.0210 - accuracy: 0.9967 - 35ms/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "29/29 - 0s - loss: 0.0208 - accuracy: 0.9967 - 77ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "29/29 - 0s - loss: 0.0206 - accuracy: 0.9967 - 36ms/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "29/29 - 0s - loss: 0.0201 - accuracy: 0.9967 - 37ms/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "29/29 - 0s - loss: 0.0201 - accuracy: 0.9967 - 34ms/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "29/29 - 0s - loss: 0.0197 - accuracy: 0.9967 - 31ms/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "29/29 - 0s - loss: 0.0193 - accuracy: 0.9967 - 33ms/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "29/29 - 0s - loss: 0.0192 - accuracy: 0.9967 - 31ms/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "29/29 - 0s - loss: 0.0190 - accuracy: 0.9967 - 49ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "29/29 - 0s - loss: 0.0190 - accuracy: 0.9967 - 43ms/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "29/29 - 0s - loss: 0.0188 - accuracy: 0.9967 - 44ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "29/29 - 0s - loss: 0.0186 - accuracy: 0.9967 - 43ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "29/29 - 0s - loss: 0.0186 - accuracy: 0.9967 - 40ms/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "29/29 - 0s - loss: 0.0184 - accuracy: 0.9967 - 35ms/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "29/29 - 0s - loss: 0.0179 - accuracy: 0.9967 - 34ms/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "29/29 - 0s - loss: 0.0178 - accuracy: 0.9967 - 37ms/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "29/29 - 0s - loss: 0.0180 - accuracy: 0.9967 - 38ms/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "29/29 - 0s - loss: 0.0174 - accuracy: 0.9967 - 33ms/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "29/29 - 0s - loss: 0.0176 - accuracy: 0.9967 - 46ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "29/29 - 0s - loss: 0.0172 - accuracy: 0.9967 - 49ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8308040c70>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(scaled_X_train, y_train, epochs=100, verbose=2) #traine itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ca9e739-3867-4899-a515-269b057cb10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#check in test\n",
    "predictions = (model.predict(scaled_X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88915ab2-7033-4955-964e-c7e3f9996527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[254,   3],\n",
       "       [  0, 196]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model\n",
    "[\"loss\", \"acc\"]\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbabde66-d6f3-4bef-a1ee-d788d31698ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99       257\n",
      "         1.0       0.98      1.00      0.99       196\n",
      "\n",
      "    accuracy                           0.99       453\n",
      "   macro avg       0.99      0.99      0.99       453\n",
      "weighted avg       0.99      0.99      0.99       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a55546a-5140-46ec-9e88-005fe51a6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "model.save(\"first_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bf5425e-b299-4d7a-92e7-018908279b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "from keras.models import load_model\n",
    "new_model = load_model(\"first_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a51779e9-c528-43ae-9732-8f276a908ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = (new_model.predict(scaled_X_test) > 0.5).astype(\"int32\")\n",
    "new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ee089-78b0-4cb1-8e37-b964780b42c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
