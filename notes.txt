Máiron Chaves

** Seja paciente, explore os dados com calma, e no final use (ou tente usar) modelos preditivos tradicionais **

Como Cientista de Dados e acadêmico, tenho constatado ao longo dos anos que uma abordagem meticulosa e criteriosa à análise de dados pode revelar que técnicas fundamentais, como a regressão linear e a regressão logística, frequentemente oferecem soluções eficazes para a vasta maioria dos desafios analíticos que enfrentamos.

Estas técnicas, embora "básicas", demonstram uma robustez impressionante na previsão e análise de impacto de variáveis preditoras.

Isso se dá não apenas pela possibilidade de interpretar os coeficientes ou odds ratios, mas também pela habilidade de avaliar a significância estatística de cada preditor através de testes t ou z, acompanhados dos respectivos valores p, ou ir direto e analisar o tamanho da estatística de teste calculada pra cada preditor.

O poder dessas ferramentas analíticas tradicionais é muitas vezes subestimado. Contudo, uma exploração de dados detalhada e bem-orientada – identificando relações lineares e não lineares, outliers, normalizando variâncias, e transformando variáveis para simetria, por exemplo, com técnicas como Box-Cox ou Yeo-Johnson para a variável resposta – pode não apenas aprimorar a compreensão do conjunto de dados em questão, mas também maximizar o desempenho desses modelos regressivos fundamentais.

Isso é complementado por uma sólida engenharia de atributos e testes de hipóteses criteriosos, aliados com um bom entendimento do contexto.

Em minha experiência, muitos projetos de ciência de dados que pareciam inicialmente demandar soluções altamente complexas e computacionalmente intensivas, como modelos baseados em Boosting, foram adequadamente resolvidos com modelos de regressão ajustados e cuidadosamente preparados.

Quando confrontados com situações onde a regressão linear ou logística não oferecem soluções completas, a introdução de regularizações – Lasso (L1) ou Ridge (L2) – na função de perda pode, na maioria das vezes, oferecer os ajustes necessários para alcançar a performance desejada.

Portanto, enfatizo a importância de não subestimar o poder das técnicas fundamentais de análise. Tomando cuidado com presença de multicolinearidade (que tende a ser eliminado durante a EDA) e a "dummy trap" caso tenha variáveis categóricas e a equação tenha intercepto.

Minha dica é :
1 - Entenda bem o contexto de negócio
2 - Entenda as variáveis (não simplesmente jogue um monte no dataset)
3 - Fique íntimo das variáveis, faça uma grandiosa análise exploratória
4- Ajuste uma regressão linear (se for uma tarefa de regressão) ou uma regressão logística (se for uma tarefa de clasificação)

ah! e na regressão logística, não deixe o threshold em 50% sem fazer uma análise de sensibilidade vs especificidade (ou uma curva de precisão vs sensibilidade) para identificar o "melhor" threshold.
